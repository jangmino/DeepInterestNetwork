{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wepick_data_header = [\n",
    "\"v\", \"u\", \"seq\", \"rgtme\", \"dt\", \"label\", \"av\", \"bq\", \"dn\", \"dot\", \"dv\", \"dvcid\", \"g\", \"lid0\",\n",
    "\"lid1\", \"lid2\", \"s\", \"ci\", \"dgid\", \"ef\", \"ls\", \"pe\", \"po\", \"pot\", \"ps\", \"set\", \"sst\", \"st\",\n",
    "\"ti1\", \"ti2\", \"ti3\", \"ti4\", \"ti5\", \"tn1\", \"tn2\", \"tn3\", \"tn4\", \"tn5\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = r'c:\\Users\\wmp\\TensorFlow\\DIN_tf_eager'\n",
    "dic = {}\n",
    "for fname in glob.glob(os.path.join(data_dir,'data*.csv')):\n",
    "    df = pd.read_csv(fname, header=None, names=wepick_data_header)\n",
    "    dic[fname] = df\n",
    "\n",
    "x = pd.concat(dic.values(), ignore_index=True)\n",
    "\n",
    "x = x[['v','u','seq', 'rgtme','dt', 'label', 'ti1', 'ti2', 'tn1', 'tn2']]\n",
    "\n",
    "# There may be NA in ti1, ti2 (배송2.0 관련?)\n",
    "x = x.reset_index(drop=True)\n",
    "x = x.dropna(how='any')\n",
    "\n",
    "x['ti1'] = x['ti1'].astype('int64')\n",
    "x['ti2'] = x['ti2'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_map(df, col_name):\n",
    "  key = sorted(df[col_name].unique().tolist())\n",
    "  m = dict(zip(key, range(len(key))))\n",
    "  df[col_name] = df[col_name].map(lambda x: m[x])\n",
    "  return m, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origin_x = x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deal_to_tn1 = dict(zip(origin_x['v'], origin_x['tn1']))\n",
    "deal_to_tn2 = dict(zip(origin_x['v'], origin_x['tn2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deal_map, deal_key = build_map(x, 'v')\n",
    "\n",
    "user_map, user_key = build_map(x, 'u')\n",
    "\n",
    "ti1_map, ti1_key = build_map(x, 'ti1')\n",
    "ti2_map, ti2_key = build_map(x, 'ti2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x.sort_values(['u','rgtme'])\n",
    "x = x.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오류 수정: v, t1으로 groupby 한 후, 값을 취하여야 한다.\n",
    "ti1_list = list(map(lambda x: x[1],[a for a, _ in x.groupby(['v', 'ti1'])]))\n",
    "ti2_list = list(map(lambda x: x[1],[a for a, _ in x.groupby(['v', 'ti2'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x.drop(columns=['ti1', 'ti2', 'dt', 'tn1', 'tn2'])\n",
    "pos = x[x['label']==1]\n",
    "neg = x[x['label']==0]\n",
    "\n",
    "x = pd.merge(pos, neg, on=['u','rgtme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary for lowest rank given deal.\n",
    "deal_slot = origin_x[['v', 'seq']]\n",
    "deal_slot = deal_slot.groupby('v').min()\n",
    "deal_slot = deal_slot['seq']\n",
    "deal_slot = deal_slot.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wepick_data = {'data':x, \n",
    "          'deal_map':deal_map, 'deal_key':deal_key,\n",
    "          'user_map':user_map, 'user_key':user_key, \n",
    "          'ti1_map':ti1_map, 'ti1_key':ti1_key,\n",
    "          'ti2_map':ti2_map, 'ti2_key':ti2_key,\n",
    "          'ti1_list':ti1_list, 'ti2_list':ti2_list,\n",
    "          'deal_slot':deal_slot\n",
    "         }\n",
    "\n",
    "with open(os.path.join(data_dir,'wepick_data.pkl'), 'wb') as f:\n",
    "    pickle.dump(wepick_data, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = []\n",
    "test_set = []\n",
    "\n",
    "# restriction is needed for DIN\n",
    "max_history = 24\n",
    "for u, hist in x.groupby('u'):\n",
    "    pos = hist['v_x'].tolist()\n",
    "    neg = hist['v_y'].tolist()\n",
    "    for i in range(1, len(pos)):\n",
    "        hist = pos[:i]\n",
    "        hist = hist[-max_history:]\n",
    "        if i != len(pos)-1:\n",
    "            train_set.append((u, hist, pos[i], 1))\n",
    "            train_set.append((u, hist, neg[i], 0))\n",
    "        else:\n",
    "            label = (pos[i], neg[i])\n",
    "            test_set.append((u, hist, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "random.shuffle(train_set)\n",
    "random.shuffle(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924410, 240012)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir,'wepick_dataset.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_set,f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(test_set,f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(ti1_list,f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump((len(user_map), len(deal_map), len(ti1_map)), f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir,'deal_to_tn.pkl'), 'wb') as f:\n",
    "    pickle.dump(deal_to_tn1,f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(deal_to_tn2,f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logs from training\n",
    "\n",
    "```Epoch 16 DONE\tCost time: 5413.38\n",
    "Epoch 17 Global_step 492000\tTrain_loss: 0.4010\tEval_GAUC: 0.8195\tEval_AUC: 0.8254\n",
    "Epoch 17 Global_step 493000\tTrain_loss: 0.4505\tEval_GAUC: 0.8212\tEval_AUC: 0.8271\n",
    "Epoch 17 Global_step 494000\tTrain_loss: 0.4460\tEval_GAUC: 0.8204\tEval_AUC: 0.8266\n",
    "Epoch 17 Global_step 495000\tTrain_loss: 0.4463\tEval_GAUC: 0.8206\tEval_AUC: 0.8270\n",
    "Epoch 17 Global_step 496000\tTrain_loss: 0.4467\tEval_GAUC: 0.8210\tEval_AUC: 0.8273\n",
    "Epoch 17 Global_step 497000\tTrain_loss: 0.4469\tEval_GAUC: 0.8189\tEval_AUC: 0.8247\n",
    "Epoch 17 Global_step 498000\tTrain_loss: 0.4487\tEval_GAUC: 0.8219\tEval_AUC: 0.8267\n",
    "Epoch 17 Global_step 499000\tTrain_loss: 0.4497\tEval_GAUC: 0.8199\tEval_AUC: 0.8254\n",
    "Epoch 17 Global_step 500000\tTrain_loss: 0.4481\tEval_GAUC: 0.8252\tEval_AUC: 0.8307\n",
    "Epoch 17 Global_step 501000\tTrain_loss: 0.4459\tEval_GAUC: 0.8220\tEval_AUC: 0.8282\n",
    "Epoch 17 Global_step 502000\tTrain_loss: 0.4459\tEval_GAUC: 0.8233\tEval_AUC: 0.8285\n",
    "Epoch 17 Global_step 503000\tTrain_loss: 0.4456\tEval_GAUC: 0.8232\tEval_AUC: 0.8291\n",
    "Epoch 17 Global_step 504000\tTrain_loss: 0.4470\tEval_GAUC: 0.8216\tEval_AUC: 0.8282\n",
    "Epoch 17 Global_step 505000\tTrain_loss: 0.4465\tEval_GAUC: 0.8194\tEval_AUC: 0.8251\n",
    "Epoch 17 Global_step 506000\tTrain_loss: 0.4467\tEval_GAUC: 0.8216\tEval_AUC: 0.8274\n",
    "Epoch 17 Global_step 507000\tTrain_loss: 0.4446\tEval_GAUC: 0.8191\tEval_AUC: 0.8250\n",
    "Epoch 17 Global_step 508000\tTrain_loss: 0.4439\tEval_GAUC: 0.8185\tEval_AUC: 0.8246\n",
    "Epoch 17 Global_step 509000\tTrain_loss: 0.4446\tEval_GAUC: 0.8180\tEval_AUC: 0.8234\n",
    "Epoch 17 Global_step 510000\tTrain_loss: 0.4450\tEval_GAUC: 0.8208\tEval_AUC: 0.8268\n",
    "Epoch 17 Global_step 511000\tTrain_loss: 0.4440\tEval_GAUC: 0.8204\tEval_AUC: 0.8264```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
